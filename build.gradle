plugins {
    id 'io.spring.dependency-management' version '1.0.9.RELEASE'														// https://plugins.gradle.org/plugin/io.spring.dependency-management
    id 'com.github.johnrengelman.shadow' version '7.1.2'																// https://github.com/johnrengelman/shadow
    id 'java'                                                                                                           // https://docs.gradle.org/current/userguide/java_plugin.html
    id 'idea'                                                                                                           // https://docs.gradle.org/current/userguide/idea_plugin.html
    id 'jacoco'                                                                                                         // https://docs.gradle.org/current/userguide/jacoco_plugin.html
}

group = 'me.mvillalobos.understanding-apache-flink'
version = '0.0.1-SNAPSHOT'
sourceCompatibility = '11'

repositories {
    mavenCentral()
}

dependencyManagement {
    ext {
        avroVersion = '1.10.1'
        awsJavaSdkVersion = '1.12.287'
        commonsCsvVersion = '1.9.0'
        commonsTextVersion = '1.8'
        flinkVersion = '1.18.1'
        flinkConnecterKafkaVersion = '3.0.1-1.18'
        flinkConnectorJdbcVersion = '3.1.1-1.17'
        hadoopVersion = '3.3.6'
        hadoopClientVersion = '3.3.6'
        hiveVersion = '3.1.3'
        hiveConnectorVersion = '3.1.3'
        hiveAntlrRuntimeVersion = '3.5.2'
        lombokVersion = '1.18.20'
        log4jVersion = '1.2.17'
        mockitoVersion = '5.4.0'
        parquetAvroVersion = '1.12.2'
        scalaVersion = '2.12'
        slf4jVersion = '1.7.36'
    }
    dependencies {
        dependency "com.amazonaws:aws-java-sdk-s3:${awsJavaSdkVersion}"
        //dependency "org.apache.avro:avro:${avroVersion}"
        dependency "org.apache.flink:flink-avro:${flinkVersion}"
        dependency "org.apache.flink:flink-java:${flinkVersion}"
        dependency "org.apache.flink:flink-streaming-java:${flinkVersion}"
        dependency "org.apache.flink:flink-s3-fs-hadoop:${flinkVersion}"
        dependency "org.apache.flink:flink-connector-kafka:${flinkConnecterKafkaVersion}"
        dependency "org.apache.flink:flink-connector-files:${flinkVersion}"
        dependency "org.apache.flink:flink-connector-jdbc:${flinkConnectorJdbcVersion}"
        dependency "org.apache.flink:flink-connector-hive_${scalaVersion}:${flinkVersion}"
        dependency "org.apache.flink:flink-table-api-java-bridge:${flinkVersion}"
        dependency "org.apache.flink:flink-sql-gateway-api:${flinkVersion}"
        dependency "org.apache.flink:flink-statebackend-rocksdb:${flinkVersion}"
        dependency "org.apache.flink:flink-state-processor-api:${flinkVersion}"
        dependency "org.apache.flink:flink-table-runtime:${flinkVersion}"
        dependency "org.apache.flink:flink-table-planner-loader:${flinkVersion}"
        dependency "org.apache.flink:flink-table-common:${flinkVersion}"
        dependency "org.apache.flink:flink-test-utils:${flinkVersion}"
        dependency "org.apache.flink:flink-table-test-utils:${flinkVersion}"
        dependency "org.apache.flink:flink-clients:${flinkVersion}"
        dependency "org.apache.flink:flink-parquet:${flinkVersion}"
        dependency "org.apache.parquet:parquet-avro:${parquetAvroVersion}"
        dependency "org.apache.hadoop:hadoop-client:${hadoopClientVersion}"
        dependency "org.apache.commons:commons-csv:${commonsCsvVersion}"
        dependency "org.apache.commons:commons-text:${commonsTextVersion}"
        dependency "org.mockito:mockito-core:${mockitoVersion}"
        dependency "org.mockito:mockito-junit-jupiter:${mockitoVersion}"
        dependency "org.slf4j:slf4j-api:${slf4jVersion}"
        dependency "org.slf4j:slf4j-log4j12:${slf4jVersion}"
        dependency "log4j:log4j:${log4jVersion}"
    }
}

configurations {
    // ide configuration marks libraries required for IDE execution only
    ide
    // shaded configuration marks libraries required in the shaded jar
    shaded 

    // always exclude these (also from transitive dependencies) since they are provided by Flink
    shaded.exclude group: 'org.apache.flink', module: 'force-shading'
    shaded.exclude group: 'com.google.code.findbugs', module: 'jsr305'
    shaded.exclude group: 'org.slf4j'
    shaded.exclude group: 'log4j'

    shaded.exclude group: 'org.apache.flink', module: 'flink-streaming-java'
    shaded.exclude group: 'org.apache.flink', module: 'flink-streaming-scala_${scalaVersion}'
    shaded.exclude group: 'org.apache.flink', module: 'flink-table-api-java-bridge'
    shaded.exclude group: 'org.apache.flink', module: 'flink-table-common'
    shaded.exclude group: 'org.apache.flink', module: "flink-statebackend-rocksdb_${scalaVersion}"
    shaded.exclude group: 'org.apache.flink', module: 'flink-clients'
    shaded.exclude group: 'org.apache.flink', module: 'flink-s3-fs-hadoop'
    shaded.exclude group: 'org.apache.hadoop', module: 'hadoop-client'
    shaded.exclude group: 'org.apache.flink', module: 'force-shading'
    shaded.exclude group: 'com.google.code.findbugs', module: 'jsr305'
    shaded.exclude group: 'org.projectlombok', module: 'lombok'

    hadoop
    hadoop.transitive true

    parquet
    parquet.transitive = true

    hiveConnector
    hiveConnector.transitive = false

    hive
    hive.transitive = false
}

dependencies {
    runtimeOnly 'org.slf4j:slf4j-log4j12'
    runtimeOnly 'log4j:log4j'
    runtimeOnly 'org.apache.flink:flink-java'

    // Flink Core APIS to be excluded from shaded jar:
    //
    // FYI, to determine if a jar should be excluded from shading, find a class
    // file in the jar file and within the flink lib directory search for that
    // Any class files in `${FLINK_HOME}/find . -name "*.jar" -exec jar tvf {} \; | grep CLASSFILE`
    // Should be part of the ide configuration
    ide 'org.apache.flink:flink-statebackend-rocksdb'
    ide 'org.apache.flink:flink-streaming-java'
    ide 'org.apache.flink:flink-s3-fs-hadoop'
    ide 'org.apache.flink:flink-table-api-java-bridge'
    ide 'org.apache.flink:flink-clients'
    ide 'org.apache.flink:flink-table-common'
    ide 'org.apache.flink:flink-table-runtime'
    ide 'org.apache.flink:flink-table-planner-loader'
    ide 'org.apache.flink:flink-sql-gateway-api'
    // ide 'org.asynchttpclient:async-http-client:2.12.3'

    // flink dependencies required in shaded jar:
    shaded 'org.apache.flink:flink-avro'
    shaded 'org.apache.flink:flink-state-processor-api'
    shaded 'org.apache.flink:flink-connector-files'
    shaded 'org.apache.flink:flink-connector-jdbc'
    shaded 'org.apache.flink:flink-connector-kafka'
    shaded 'org.apache.flink:flink-parquet'
    shaded "org.apache.flink:flink-connector-hive_${scalaVersion}"

    // Other non-flink related dependencies required in shaded jar
    shaded 'org.apache.commons:commons-csv'
    shaded 'org.apache.commons:commons-text'
    shaded 'com.amazonaws:aws-java-sdk-s3'
    shaded('org.apache.parquet:parquet-avro') {
        exclude group: 'org.apache.hadoop', module: 'hadoop-client'
        exclude group: 'it.unimi.dsi', module: 'fastutil'
    }

    // Other non-flink dependencies not in shaded-jar
    ide('org.apache.hadoop:hadoop-client') { // required to test locally with S3 and RocksDB
        exclude group: 'org.apache.avro', module: 'avro'
    }
    testImplementation 'org.junit.jupiter:junit-jupiter'
    testImplementation ('org.apache.flink:flink-test-utils') {
        exclude module: 'log4j'
        exclude group: 'log4j'
        exclude group: 'org.apache.logging.log4j'
    }
    testImplementation ('org.apache.flink:flink-table-test-utils') {
        exclude module: 'log4j'
        exclude group: 'log4j'
        exclude group: 'org.apache.logging.log4j'
    }
    testImplementation "org.apache.flink:flink-streaming-java:${flinkVersion}:tests"
    testImplementation 'org.mockito:mockito-core'
    testImplementation 'org.mockito:mockito-junit-jupiter'

    compileOnly "org.projectlombok:lombok:${lombokVersion}"
    testCompileOnly "org.projectlombok:lombok:${lombokVersion}"

    annotationProcessor "org.projectlombok:lombok:${lombokVersion}"
    testAnnotationProcessor "org.projectlombok:lombok:${lombokVersion}"

    hadoop 'org.apache.hadoop:hadoop-client'
    parquet 'org.apache.flink:flink-parquet'
    hiveConnector "org.apache.flink:flink-connector-hive_${scalaVersion}"
    hive "org.apache.hive:hive-exec:${hiveVersion}"
    hive "org.antlr:antlr-runtime:${hiveAntlrRuntimeVersion}"
}

// make compileOnly dependencies available for tests:
sourceSets {
    main.compileClasspath += configurations.shaded
    main.compileClasspath += configurations.ide
    main.runtimeClasspath += configurations.shaded
    main.runtimeClasspath += configurations.ide

    test.compileClasspath += configurations.shaded
    test.compileClasspath += configurations.ide
    test.runtimeClasspath += configurations.shaded
    test.runtimeClasspath += configurations.ide

    javadoc.classpath += configurations.shaded
    javadoc.classpath += configurations.ide
}

shadowJar {
    configurations = [project.configurations.shaded]
    zip64 true

    manifest {
        attributes 'Main-Class': 'me.mvillalobos.presentations.flink.understanding.UnderstandingApacheFlinkApp'
    }

    archiveBaseName = 'understanding-apache-flink'
    archiveVersion = ''
    mergeServiceFiles()
}

test {
    useJUnitPlatform()
}

task downloadHadoopDependencies(type: Copy) {
    from configurations.hadoop
    into 'build/libs/hadoop/'
}

task downloadParquetDependencies(type: Copy) {
    from configurations.parquet
    into 'build/libs/parquet/'
}

task downloadHiveConnector(type: Copy) {
    from configurations.hiveConnector
    into 'build/libs/connectors/'
}

task downloadHiveDependencies(type: Copy) {
    from configurations.hive
    into 'build/libs/hive/'
}


